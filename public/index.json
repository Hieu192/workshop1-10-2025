[{"uri":"https://Hieu192.github.io/workshop1-10-2025/5-stepoptimal/5.1-createsqsdead/","title":"Create AMI for App Tier","tags":[],"description":"","content":"Why do we need AMIs? Reproduce configurations easily - Once you have an instance configured the way you want, with all necessary software, settings etc., you can create an AMI from it. Then launching new instances from that AMI ensures all instances have the same baseline configuration automatically. Standardize environments - AMIs help maintain consistency across your environments. For example, you may have an AMI configured for a web server role that contains the necessary web server software and configurations. All new web server instances would use this standardized AMI. Backup and recovery - AMIs act as machine snapshots that can be used for backup, disaster recovery or to reproduce instances that may have failed. If an existing instance fails or needs to be replaced, launching a new one from the AMI is quicker than reconfiguring from scratch. Auto scaling - When using auto scaling groups to dynamically scale your fleet size based on demand, AMIs ensure all new instances added by auto scaling have the required configuration already in place. Create AMI from EC2 Instance Access EC2 service:\nChoose Instances from the sidebar Select instance My App Server 1 Click Actions, then click Image and template and choose Create image In the create image interface:\nFill in Image name with AppTierImage Fill in Image description with App tier Scroll down to the bottom and click Create image "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/3-processorderhandler/3.1-createsqs/","title":"Create database subnet group","tags":[],"description":"","content":"What is Database subnet group and why do we need it? A database subnet group is a collection of subnets that you create in your VPC. When you create a database instance, you need to specify a database subnet group. The database subnet group must contain at least one subnet in each AZ. The database subnet group ensures that the database instance can be deployed across multiple AZs for high availability.\nCreate database subnet group Find and access the RDS service Choose Subnet groups in the sidebar and click Create DB subnet group In the create DB subnet group interface:\nName fill in db-subnet-group Description fill in db-subnet-group VPC choose my-vpc In the Add subnets section:\nAZ choose ap-southeast-1a and ap-southeast-1b Subnets choose Private DB Subnet 1 and Private DB Subnet 2 (you can go back to the list of subnets, see the CIDR of each subnet to choose the right one) Then click Create Complete creating Subnet group. "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/2-preparationsteps/2.1-createtabledynamo/","title":"Create DynamoDB Tables","tags":[],"description":"","content":"Create DynamoDB Tables In this step, we will create the necessary DynamoDB tables for our microservice application.\nCreate ProductTable Access AWS Console and navigate to DynamoDB service.\nClick Create table.\nConfigure table settings:\nTable name: ProductTable Partition key: productId (String) Keep other settings as default and click Create table.\nCreate BasketTable Click Create table again.\nConfigure table settings:\nTable name: BasketTable Partition key: userId (String) Keep other settings as default and click Create table.\nCreate OrderingTable Click Create table again.\nConfigure table settings:\nTable name: OrderingTable Partition key: orderId (String) Keep other settings as default and click Create table.\nWait for all tables to be created successfully.\n"},{"uri":"https://Hieu192.github.io/workshop1-10-2025/4-apigateway/4.1-createrestapi/","title":"Create EC2 Server","tags":[],"description":"","content":"Create EC2 Instances for App Tier Find and select the EC2 service. Select Instances in the sidebar, then click Launch instances. Name and tags fill in My App Server 1 In the AMI section:\nselect Amazon Linux AMI select Amazon Linux 2 AMI (HVM) In the Key pair section, we choose Proceed without a key pair because we will connect the EC2 instance through AWS Systems Manager Session Manager. In the Network settings section:\nVPC select my-vpc Subnet select Private Subnet 1 Auto-assign public IP select Enable SG select Select existing security group Common SG select AppTier-SG In the Advanced details section, IAM instance profile select ec2role we created above Click Launch instance Complete creating EC2 instance for a server in AppTier in private subnet 1 "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/","title":"Deploy fullstack app with three-tier architecture","tags":[],"description":"","content":"Deploy fullstack app with three-tier architecture Overview In this workshop, we will deploy a fullstack application (Spring Boot, React, MySQL) with three tier architecture. Then find out the definition, feature of each service used in this architecture.\nContent Introduction Preparation steps Create database with RDS Deploy App tier Create Internal LB and ASG Deploy Web tier Create External LB and ASG Demo web after successful deployment Clean up resources "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/1-introduce/","title":"Introduction","tags":[],"description":"","content":"Introduction to Microservice Architecture on AWS The system is designed based on the Serverless Microservices Architecture on AWS Cloud, consisting of three main microservices:\nProduct Microservice – manages product lists and product information Basket Microservice – manages users’ shopping carts Order Microservice – processes orders and payment transactions Each microservice operates independently and is fully implemented using serverless services such as API Gateway, AWS Lambda, and Amazon DynamoDB.\nSystem Workflow:\nThe User accesses the application and signs in through Amazon Cognito, the authentication and user management service provided by AWS. After authentication, the user sends API requests to AWS API Gateway. API Gateway routes each request to the corresponding microservice. The Product Microservice handles requests for product data — the Lambda function processes the logic and retrieves data from the DynamoDB Table. The Basket Microservice manages cart operations (add, remove, or update items). When the user clicks Checkout, this service publishes a Checkout Event to the AWS EventBridge Event Bus. AWS EventBridge receives the event and, based on its EventBridge Rule, routes it to an AWS SQS Queue. The Order Microservice listens to the SQS Queue, consumes new events, and triggers its Lambda function to create an order in the DynamoDB Table. The entire process is monitored through Amazon CloudWatch, while access and permissions are managed by AWS IAM. Benefits of the Architecture:\nService Isolation: Each microservice has its own logic and database, making it easier to scale and maintain. Automatic Scaling: Lambda automatically scales based on incoming request volume, with no infrastructure management required. Event-Driven Integration: EventBridge and SQS enable asynchronous communication between services, reducing latency and increasing flexibility. Strong Monitoring and Security: CloudWatch and IAM ensure system security and provide detailed monitoring for all components. Serverless Operation: The entire system is serverless, reducing operational costs and improving overall efficiency. "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/6-cognito/6.1-createuserpool/","title":"Update Nginx Configuration File","tags":[],"description":"","content":"Update Nginx Configuration File Open the nginx.conf file from the cloned project Then change line 58 in the file to the DNS Name of the app-tier-internal-lb load balancer "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/4-apigateway/4.2-testapi/","title":"Connect to EC2 instance","tags":[],"description":"","content":"Connect to EC2 instance On the EC2 instances interface, select the instance you just created and click Connect Switch to the Session Manager tab and click Connect Successfully connect to the instance Run the command sudo -su ec2-user to switch from user to ec2-user, and have root administrative rights for the instance Then run the command ping 8.8.8.8 (IP address of Google’s DNS server) to test whether our instance can connect to the outside internet through igw or not "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/3-processorderhandler/3.2-createeventbridgerule/","title":"Create database instance","tags":[],"description":"","content":"Create database instance In the Amazon RDS interface, select Databases in the sidebar and then click Create database In the Create database interface:\nCreation method select Standard create Engine type select MySQL Templates select Dev/Test, Deployment options select Multi-AZ DB instance (to create the main instance in the current AZ, and a clone instance in the remaining AZ defined in the db subnet group to prevent failover) → This deployment method will be best practice as it meets the criteria of High availability and Data redundancy But we can choose another option is Free tier to be suitable for the scope of the problem, and save costs In the Settings section:\nDB instance identifier fill in database-1 Master username fill in admin Master password fill in 12345678 In the Connectivity section:\nComputer resource select Dont connect to EC2 VPC select my-vpc DB subnet group select db-subnet-group we created Public access select No (select Yes if you want to test connection from public network) VPC SG select Choose existing Existing VPC SG select DataTier-SG AZ select ap-southeast-1a In the Additional configuration section, fill in the db name as demodb (master name: admin, pass: 12345678) Scroll down to the bottom and select Create database: Complete creating the database instance Reconfigure to test connection from public network To be able to test the connection to the endpoint of the newly created db from the public network, we need to reconfigure some things as follows (after testing, remember to return everything to the initial state)\nGo to the private-db-route-table route table, add a new route with destination 0.0.0.0/0 and target internet gateway we created In the DataTier-SG security group, add a new inbound rule to allow All traffic access Update the status of Public access in the Connectivity section in the db instance from No to Yes Test connection to the endpoint of the newly created db instance In the MySQL Workbench software, create a new connection:\nConnection Name fill in db-ws-01 Hostname copy and paste the endpoint of the newly created db instance Port fill in 3306 Username fill in admin Password click Store in Vault then enter 12345678 Finally, click Test Connection If the connection is successful, the following message will appear: Access file application.properties and reconfigure datasource url, username and password as shown below Run app and check in the connection just created in MySQL, we see that the tables have been auto-generated thanks to the code first mechanism (just for testing because in this workshop we will use database first) "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/3-processorderhandler/3.3-triggerlambdatosqs/","title":"Create database instance","tags":[],"description":"","content":"Create database instance In the Amazon RDS interface, select Databases in the sidebar and then click Create database In the Create database interface:\nCreation method select Standard create Engine type select MySQL Templates select Dev/Test, Deployment options select Multi-AZ DB instance (to create the main instance in the current AZ, and a clone instance in the remaining AZ defined in the db subnet group to prevent failover) → This deployment method will be best practice as it meets the criteria of High availability and Data redundancy But we can choose another option is Free tier to be suitable for the scope of the problem, and save costs In the Settings section:\nDB instance identifier fill in database-1 Master username fill in admin Master password fill in 12345678 In the Connectivity section:\nComputer resource select Dont connect to EC2 VPC select my-vpc DB subnet group select db-subnet-group we created Public access select No (select Yes if you want to test connection from public network) VPC SG select Choose existing Existing VPC SG select DataTier-SG AZ select ap-southeast-1a In the Additional configuration section, fill in the db name as demodb (master name: admin, pass: 12345678) Scroll down to the bottom and select Create database: Complete creating the database instance Reconfigure to test connection from public network To be able to test the connection to the endpoint of the newly created db from the public network, we need to reconfigure some things as follows (after testing, remember to return everything to the initial state)\nGo to the private-db-route-table route table, add a new route with destination 0.0.0.0/0 and target internet gateway we created In the DataTier-SG security group, add a new inbound rule to allow All traffic access Update the status of Public access in the Connectivity section in the db instance from No to Yes Test connection to the endpoint of the newly created db instance In the MySQL Workbench software, create a new connection:\nConnection Name fill in db-ws-01 Hostname copy and paste the endpoint of the newly created db instance Port fill in 3306 Username fill in admin Password click Store in Vault then enter 12345678 Finally, click Test Connection If the connection is successful, the following message will appear: Access file application.properties and reconfigure datasource url, username and password as shown below Run app and check in the connection just created in MySQL, we see that the tables have been auto-generated thanks to the code first mechanism (just for testing because in this workshop we will use database first) "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/2-preparationsteps/2.2-createiam/","title":"Create IAM Roles","tags":[],"description":"","content":"Create IAM Policies and Roles for Lambda Functions We will create custom policies with minimal required permissions, then create roles and attach the policies.\nStep 1: Create Custom Policies Create ProductLambdaPolicy Navigate to IAM service in AWS Console.\nClick Policies in the left sidebar, then Create policy.\nSelect JSON tab and paste the following policy:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:Scan\u0026#34;, \u0026#34;dynamodb:Query\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:*:*:table/ProductTable\u0026#34; } ] } Click Next.\nPolicy name: ProductLambdaPolicy\nClick Create policy.\nCreate BasketLambdaPolicy Create a new policy with the following JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:UpdateItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:*:*:table/BasketTable\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;events:PutEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:events:*:*:event-bus/default\u0026#34; } ] } Policy name: BasketLambdaPolicy Create OrderingLambdaPolicy Create a new policy with the following JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:Scan\u0026#34;, \u0026#34;dynamodb:Query\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:*:*:table/OrderingTable\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;sqs:ReceiveMessage\u0026#34;, \u0026#34;sqs:DeleteMessage\u0026#34;, \u0026#34;sqs:GetQueueAttributes\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sqs:*:*:OrderingQueue\u0026#34; } ] } Policy name: OrderingLambdaPolicy Step 2: Create IAM Roles Create ProductLambdaRole Click Roles in the left sidebar, then Create role.\nSelect AWS service and choose Lambda.\nClick Next.\nSearch and select policy: ProductLambdaPolicy\nClick Next.\nRole name: ProductLambdaRole\nClick Create role.\nCreate BasketLambdaRole Repeat the same steps with: Role name: BasketLambdaRole Attach policy: BasketLambdaPolicy Create OrderingLambdaRole Repeat the same steps with: Role name: OrderingLambdaRole Attach policy: OrderingLambdaPolicy Verification After completion, you will have:\n3 custom policies with minimal required permissions 3 corresponding IAM roles for each Lambda function "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/5-stepoptimal/5.2-createindex/","title":"Create Target group for App Tier","tags":[],"description":"","content":"Create Target group for App Tier In the EC2 Dashboard, click on Target Groups under Load Balancing at sidebar, and then click on Create target group. In the interface of creating Target group:\nTarget group name fill in AppTierTargetGroup. Protocol: HTTP, Port: 8080 VPC choose my-vpc Scroll down and click Next then click Create target group. Finish creating target group "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/2-preparationsteps/","title":"Preparation Steps","tags":[],"description":"","content":"Preparation Steps In this section, we will prepare the necessary AWS resources for our serverless microservice application.\nContent Create DynamoDB Tables Create IAM Roles Create Lambda Functions "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/6-cognito/6.2-configureapigateway/","title":"Upload Application Source Code to Amazon S3","tags":[],"description":"","content":"Upload Application Source Code to Amazon S3 Go to the library-app-fe folder under local, delete the node_modules folder (if any) Access the created S3 bucket, drag and drop the library-app-fe folder and nginx.config file under local to the bucket to upload the folder and file to the bucket. "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/6-cognito/6.3-updatecodelambda/","title":"Connect to EC2 instance","tags":[],"description":"","content":"Connect to EC2 instance Similar to connecting to the app server instance, we connect through Session manager. Switch to ec2-user. Check the connection by pinging the ip of the Google DNS server → connected to the internet through IGW. Download NPM to the instance:\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.38.0/install.sh | bash source ~/.bashrc to reload the bash shell configuration file to apply the npm just downloaded Run nvm install 16 then run nvm use 16 to download and use Node.js version 16 To copy code from the library-app-fe folder from the S3 bucket we run the following commands:\ncd to go to the user’s home directory aws s3 cp s3://demowebapp-workshop-01/library-app-fe/ web-tier --recursive to copy all files from the library-app-fe folder and its sub-folders to the web-tier folder on the instance (if the web-tier folder does not exist, the instance will automatically create a new folder) Download the dependencies:\ncd web-tier to access the folder ls -ltr to list the files and sub-folders of web-tier npm install to download the necessary libraries or dependencies npm run build to build the source code sudo amazon-linux-extras install nginx1 -y to download nginx (nginx acts as a web server to help the app run on port 80, as well as help direct API calls to the internal load balancer) Config Nginx:\ncd /etc/nginx ls We will see the nginx.conf file in the nginx folder. We need to delete this file and replace it with the file we have configured and uploaded to the s3 bucket. sudo rm nginx.conf sudo aws s3 cp s3://demowebapp-workshop-01/nginx.conf . to copy the file from the bucket to the nginx folder sudo service nginx restart to restart Nginx chmod -R 755 /home/ec2-user to grant Nginx access to all files sudo chkconfig nginx on to run the Nginx service automatically every time the instance restarts "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/3-processorderhandler/","title":"Create Database with RDS","tags":[],"description":"","content":"What is RDS? Amazon Relational Database Service (Amazon RDS) is a managed service that makes it easy to set up, operate, and scale a relational database in the cloud. It provides cost-efficient and resizable capacity, while managing time-consuming database administration tasks, freeing you to focus on your applications and business.\nContent Create database subnet group Create database instance "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/2-preparationsteps/2.3-createlambda/","title":"Create Lambda Functions","tags":[],"description":"","content":"Create Lambda Functions In this step, we will create Lambda functions for our microservices.\nCreate ProductFunction Navigate to Lambda service in AWS Console.\nClick Create function.\nConfigure function:\nChoose Author from scratch Function name: ProductFunction Runtime: Node.js 20.x Architecture: x86_64 Execution role: Use an existing role → ProductLambdaRole Click Create function.\nReplace the default code with:\nimport { DynamoDBClient } from \u0026#34;@aws-sdk/client-dynamodb\u0026#34;; import { DynamoDBDocumentClient, ScanCommand, GetCommand } from \u0026#34;@aws-sdk/lib-dynamodb\u0026#34;; const client = new DynamoDBClient({}); const ddbDocClient = DynamoDBDocumentClient.from(client); const tableName = \u0026#34;ProductTable\u0026#34;; export const handler = async (event) =\u0026gt; { console.log(\u0026#34;Event received:\u0026#34;, JSON.stringify(event)); let responseBody; let statusCode = 200; const httpMethod = event.httpMethod; const pathParams = event.pathParameters; try { if (httpMethod === \u0026#34;GET\u0026#34;) { if (pathParams \u0026amp;\u0026amp; pathParams.productId) { // Get specific product const params = { TableName: tableName, Key: { productId: pathParams.productId } }; const { Item } = await ddbDocClient.send(new GetCommand(params)); responseBody = Item ? Item : { message: \u0026#34;Product not found.\u0026#34; }; if (!Item) statusCode = 404; } else { // Get all products const params = { TableName: tableName }; const { Items } = await ddbDocClient.send(new ScanCommand(params)); responseBody = Items; } } else { statusCode = 400; responseBody = { message: \u0026#34;Unsupported method\u0026#34; }; } } catch (err) { console.error(err); statusCode = 500; responseBody = { message: \u0026#34;Internal server error\u0026#34;, error: err.message }; } return { statusCode: statusCode, headers: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; }, body: JSON.stringify(responseBody) }; }; Click Deploy. Create BasketFunction Create another function with:\nFunction name: BasketFunction Runtime: Node.js 20.x Execution role: BasketLambdaRole Replace code with:\nimport { DynamoDBClient } from \u0026#34;@aws-sdk/client-dynamodb\u0026#34;; import { DynamoDBDocumentClient, PutCommand } from \u0026#34;@aws-sdk/lib-dynamodb\u0026#34;; import { EventBridgeClient, PutEventsCommand } from \u0026#34;@aws-sdk/client-eventbridge\u0026#34;; const ddbClient = new DynamoDBClient({}); const ddbDocClient = DynamoDBDocumentClient.from(ddbClient); const ebClient = new EventBridgeClient({}); const basketTable = \u0026#34;BasketTable\u0026#34;; export const handler = async (event) =\u0026gt; { console.log(\u0026#34;Event received:\u0026#34;, JSON.stringify(event)); const { httpMethod, path, body } = event; let responseBody; let statusCode = 200; try { if (httpMethod === \u0026#34;POST\u0026#34; \u0026amp;\u0026amp; path.includes(\u0026#34;/checkout\u0026#34;)) { // Handle checkout const checkoutData = JSON.parse(body || \u0026#39;{}\u0026#39;); if (!checkoutData.userId) { return { statusCode: 400, body: JSON.stringify({ message: \u0026#34;userId is required for checkout.\u0026#34; }) }; } // Send event to EventBridge const eventParams = { Entries: [{ Source: \u0026#34;com.ecommerce.basket\u0026#34;, DetailType: \u0026#34;CheckoutEvent\u0026#34;, Detail: JSON.stringify(checkoutData), EventBusName: \u0026#34;default\u0026#34; }] }; await ebClient.send(new PutEventsCommand(eventParams)); console.log(\u0026#34;Checkout event sent to EventBridge.\u0026#34;); responseBody = { message: \u0026#34;Checkout processing started\u0026#34;, eventData: checkoutData }; } else if (httpMethod === \u0026#34;POST\u0026#34; \u0026amp;\u0026amp; path.includes(\u0026#34;/basket\u0026#34;)) { // Update basket const basketData = JSON.parse(body || \u0026#39;{}\u0026#39;); if (!basketData.userId) { return { statusCode: 400, body: JSON.stringify({ message: \u0026#34;userId is required.\u0026#34; }) }; } const params = { TableName: basketTable, Item: basketData }; await ddbDocClient.send(new PutCommand(params)); responseBody = { message: \u0026#34;Basket updated\u0026#34;, basket: basketData }; } else { statusCode = 400; responseBody = { message: \u0026#34;Unsupported method or path\u0026#34; }; } } catch (err) { console.error(err); statusCode = 500; responseBody = { message: \u0026#34;Internal server error\u0026#34;, error: err.message }; } return { statusCode: statusCode, headers: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; }, body: JSON.stringify(responseBody) }; }; Click Deploy. Create OrderingFunction Create another function with:\nFunction name: OrderingFunction Runtime: Node.js 20.x Execution role: OrderingLambdaRole Replace code with:\nimport { DynamoDBClient } from \u0026#34;@aws-sdk/client-dynamodb\u0026#34;; import { DynamoDBDocumentClient, PutCommand, ScanCommand } from \u0026#34;@aws-sdk/lib-dynamodb\u0026#34;; import { randomUUID } from \u0026#34;crypto\u0026#34;; const ddbClient = new DynamoDBClient({}); const ddbDocClient = DynamoDBDocumentClient.from(ddbClient); const orderTable = \u0026#34;OrderingTable\u0026#34;; export const handler = async (event) =\u0026gt; { console.log(\u0026#34;Event received:\u0026#34;, JSON.stringify(event)); // Handle SQS messages if (event.Records) { console.log(\u0026#34;Processing SQS message...\u0026#34;); try { for (const record of event.Records) { const sqsBody = JSON.parse(record.body); const checkoutEventData = sqsBody.detail; console.log(\u0026#34;Checkout data from SQS:\u0026#34;, checkoutEventData); const orderId = randomUUID(); const orderParams = { TableName: orderTable, Item: { orderId: orderId, userId: checkoutEventData.userId, items: checkoutEventData.items, status: \u0026#34;PENDING\u0026#34;, createdAt: new Date().toISOString() } }; await ddbDocClient.send(new PutCommand(orderParams)); console.log(`Order ${orderId} saved successfully.`); } return { message: \u0026#34;SQS messages processed successfully.\u0026#34; }; } catch (err) { console.error(\u0026#34;Error processing SQS message:\u0026#34;, err); throw err; } } // Handle API Gateway requests else if (event.httpMethod) { console.log(\u0026#34;Processing API Gateway request...\u0026#34;); if (event.httpMethod === \u0026#34;GET\u0026#34;) { try { const params = { TableName: orderTable }; const { Items } = await ddbDocClient.send(new ScanCommand(params)); return { statusCode: 200, headers: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; }, body: JSON.stringify(Items) }; } catch (err) { console.error(err); return { statusCode: 500, body: JSON.stringify({ message: \u0026#34;Internal server error\u0026#34; }) }; } } } console.warn(\u0026#34;Unknown event type\u0026#34;); return { statusCode: 400, body: JSON.stringify({ message: \u0026#34;Unsupported event source\u0026#34; }) }; }; Click Deploy. All Lambda functions have been created successfully!\n"},{"uri":"https://Hieu192.github.io/workshop1-10-2025/6-cognito/6.4-createusertoken/","title":"Create EC2 instance","tags":[],"description":"","content":"Create EC2 instance Similar to creating an instance for the App server, create an instance for the web server with the following changes:\nInstance name fill in My Web Server 1 Subnet select Public Subnet 1 Security group select WebTier-SG Advanced details, IAM instance profile select ec2role Finally, select Launch instance Complete creating an EC2 instance for the web server "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/4-apigateway/","title":"Deploy Application Tier","tags":[],"description":"","content":"Deploy Application Tier In this section, we will create an EC2 instance in a private subnet, connect to the instance, install MySQL on the instance, and run our app on the instance.\nContent Create EC2 instance Connect to EC2 instance Install MySQL on instance Run app on instance "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/5-stepoptimal/","title":"Create Internal Load Balancer and Auto Scaling Group","tags":[],"description":"","content":"Introduction In this section, we will create an Internal Load Balancer to balance the traffic from the Web Tier to the App Tier and an Auto Scaling Group for the App Tier.\nContent: Create AMI for App Tier Create Target Group Create Internal Load Balancer Create Launch Template for App Tier Create Auto Scaling Group "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/6-cognito/","title":"Deploy Web Tier","tags":[],"description":"","content":"Introduction In this section, we will deploy the Web Tier by uploading the source code of the application to Amazon S3 and deploying the application on Amazon EC2. In addition, we will use Nginx in this workshop. Nginx will act as a web server that we will configure to run the application on port 80, as well as help redirect API requests from the Web Tier to the App Tier through the Internal Load Balancer.\nContents: Update Nginx Configuration File Upload Application Source Code to Amazon S3 Create EC2 Instance Connect to EC2 Instance "},{"uri":"https://Hieu192.github.io/workshop1-10-2025/7-cleanupresource/","title":"Create External Load Balancer and Auto Scaling Group","tags":[],"description":"","content":""},{"uri":"https://Hieu192.github.io/workshop1-10-2025/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://Hieu192.github.io/workshop1-10-2025/tags/","title":"Tags","tags":[],"description":"","content":""}]